{"title":"Ajax处理之半次元周榜部分爬虫","uid":"d2a2df109c822658374a25b0dbe541ec","slug":"Ajax处理之半次元周榜部分爬虫","date":"2020-07-11T11:51:17.000Z","updated":"2023-09-06T07:11:44.028Z","comments":true,"path":"api/articles/Ajax处理之半次元周榜部分爬虫.json","keywords":null,"cover":[],"content":"<p>Ajax数据爬取的一个简单的例子</p>\n<span id=\"more\"></span>\n\n<h4 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h4><p>这个是在动态页面的爬虫，而一般来说，现在大部分动态页面通过Ajax加载的，Ajax即Asynchronous Javascript and XML，这个Ajax的作用就是可以让页面在不被全部刷新的情况下可以进行全部更新，我们不能直接用requests.get(url)直接爬取页面的源代码，因为一般来说很难爬到或爬不全我们需要的信息。</p>\n<h4 id=\"确定页面的类型\"><a href=\"#确定页面的类型\" class=\"headerlink\" title=\"确定页面的类型\"></a>确定页面的类型</h4><p>我们先打开半次元周榜（<a href=\"https://bcy.net/illust/toppost100%EF%BC%89%EF%BC%8C%E5%BD%93%E6%88%91%E4%BB%AC%E4%B8%8B%E6%BB%91%E5%88%B0%E5%BA%95%E9%83%A8%E6%97%B6%EF%BC%8C%E4%BC%9A%E5%8F%91%E7%8E%B0%E5%BA%95%E9%83%A8**%E6%96%B0**%E5%8A%A0%E8%BD%BD%E4%BA%86%E4%B8%80%E4%BA%9B%E5%9B%BE%E7%89%87%EF%BC%8C%E6%88%91%E4%BB%AC%E5%8F%AF%E4%BB%A5%E7%A1%AE%E5%AE%9A%E8%BF%99%E4%B8%AA%E7%BD%91%E5%9D%80%E7%94%A8Ajax%E5%8A%A0%E8%BD%BD%E7%9A%84%E3%80%82\">https://bcy.net/illust/toppost100），当我们下滑到底部时，会发现底部<strong>新</strong>加载了一些图片，我们可以确定这个网址用Ajax加载的。</a></p>\n<h4 id=\"Ajax分析\"><a href=\"#Ajax分析\" class=\"headerlink\" title=\"Ajax分析\"></a>Ajax分析</h4><p>接下来打开开发者工具(Ctrl+Shift+I或F12)，然后打开NetWork, 为了更快的找到自己需要找的信息，我们可以直接点击“XHR”（XMLHttpRequests，这个与Ajax加载有关），最后在不断的下滑中，会发现这个XHR界面不断出现一些东西，其中一些东西就是我们需要找的目标。</p>\n<p><img src=\"https://raw.githubusercontent.com/liuweixu/cdn/master/Python-crawler/Ajax.jpg\"></p>\n<p>这个Preview界面我们可以看出里面有一些我们需要的信息，对了，这个没有JS加密，所以可以直接爬，但是 ，这个比较难以用Beautifulsoup或Xpath解析，不过，由于它是json格式的，可以利用json的特点来查找我们需要的信息（即图片的链接）。对了，为了方便分析和查找，推荐使用Google的<strong>json-handle</strong>插件，这个会让Preview的json更有条理和清晰（直接点击“itemInfo?p&#x3D;4….”，就可以看见这个处理好的json）。</p>\n<p>效果图：</p>\n<p><img src=\"https://raw.githubusercontent.com/liuweixu/cdn/master/Python-crawler/Ajax1.png\"></p>\n<h4 id=\"Ajax爬取\"><a href=\"#Ajax爬取\" class=\"headerlink\" title=\"Ajax爬取\"></a>Ajax爬取</h4><ul>\n<li><p>首先，我们确定爬取的链接，点击Headers，可以看见有Requests URL，我们可以看出这个请求链接有个规律，除了p有所不同外，其他是一样的，我们可以认为这个p是page，页码，同时，这个链接里面是用“&amp;”链接各个部分的。于是可以利用urllib的urlencode，先构造合适的参数，然后用urlencode解析这个参数，进而得到链接，然后就用requests.get()直接爬取这个json，为了应对可能的反爬，可以添加请求头。</p>\n<div class=\"language-txt\"><button title=\"Copy code\" class=\"copy\"></button><span class=\"lang\">txt</span><pre class=\"shiki material-theme-palenight\" style=\"background-color: #1a1a1a\" tabindex=\"0\"><code><span class=\"line\"><span style=\"color: #babed8\">def getHTMLText(page):</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">    # 构建请求头</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">    headers = &#123;</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        &quot;accept&quot;: &quot;*/*&quot;,</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        &quot;accept-encoding&quot;: &quot;gzip, deflate, br&quot;,</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        &quot;accept-language&quot;: &quot;zh-CN,zh;q=0.9,en-CN;q=0.8,en;q=0.7,ja-CN;q=0.6,ja;q=0.5&quot;,</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        &quot;x-requested-with&quot;: &quot;xmlhttprequest&quot;,</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        &quot;user-agent&quot;: &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 \\</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        (KHTML, like Gecko) Chrome/77.0.3865.90 Safari/537.36&quot;</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">    &#125;</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">    # 构建参数</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">    params = &#123;</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        &#39;p&#39;: page,</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        &#39;ttype&#39;: &#39;illust&#39;,</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        &#39;sub_type&#39;: &#39;week&#39;,</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        &#39;date&#39;: &#39;20190923&#39;</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">    &#125;</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">    # 利用urlencode将参数解析为带有&quot;&amp;&quot;链接的的字符串，和base_url组成可以访问的链接。</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">    url = base_url + urlencode(params)</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">    txt = requests.get(url, headers=headers, timeout=50)</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">    if txt.status_code == 200:</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        return txt.json()  # 返回json文件</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">    else:</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        return None</span></span></code></pre></div></li>\n<li><p>然后利用这个爬取得到的json，我们可以利用json的特点（类似于字典）一步一步得到我们需要的图片链接：</p>\n<div class=\"language-txt\"><button title=\"Copy code\" class=\"copy\"></button><span class=\"lang\">txt</span><pre class=\"shiki material-theme-palenight\" style=\"background-color: #1a1a1a\" tabindex=\"0\"><code><span class=\"line\"><span style=\"color: #babed8\"># 解析，不过由于返回的是json文件，可以利用json的特点（类似字典）来查找自己需要找的信息。</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">def parse_page(json):</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">    if json:</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        for i in range(20):</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">            ls = json[&#39;data&#39;][&#39;top_list_item_info&#39;][i][&#39;item_detail&#39;][&#39;multi&#39;]</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">            for item in ls:</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">                links.append(item[&#39;path&#39;])</span></span></code></pre></div></li>\n<li><p>最后就是保存图片，可以利用保存txt文件的方式来保存图片，只不过后缀名需要从“.txt”改为”.jpg”或”.png”等等。</p>\n<div class=\"language-txt\"><button title=\"Copy code\" class=\"copy\"></button><span class=\"lang\">txt</span><pre class=\"shiki material-theme-palenight\" style=\"background-color: #1a1a1a\" tabindex=\"0\"><code><span class=\"line\"><span style=\"color: #babed8\">def Image_save(links, num):</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">    for i in range(1, num + 1):</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        html = requests.get(links[i - 1])</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        with open(&quot;./Image/&#123;&#125;.jpg&quot;.format(i), &quot;wb&quot;) as f:</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">            f.write(html.content)</span></span></code></pre></div></li>\n</ul>\n<h4 id=\"全部代码：\"><a href=\"#全部代码：\" class=\"headerlink\" title=\"全部代码：\"></a>全部代码：</h4><div class=\"language-txt\"><button title=\"Copy code\" class=\"copy\"></button><span class=\"lang\">txt</span><pre class=\"shiki material-theme-palenight\" style=\"background-color: #1a1a1a\" tabindex=\"0\"><code><span class=\"line\"><span style=\"color: #babed8\"># encoding=&#39;utf-8&#39;</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">import requests</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">from urllib.parse import urlencode</span></span>\n<span class=\"line\"><span style=\"color: #babed8\"></span></span>\n<span class=\"line\"><span style=\"color: #babed8\">links = []</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">base_url = &quot;https://bcy.net/apiv3/rank/list/itemInfo?&quot;</span></span>\n<span class=\"line\"><span style=\"color: #babed8\"></span></span>\n<span class=\"line\"><span style=\"color: #babed8\"></span></span>\n<span class=\"line\"><span style=\"color: #babed8\">def getHTMLText(page):</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">    # 构建请求头</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">    headers = &#123;</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        &quot;accept&quot;: &quot;*/*&quot;,</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        &quot;accept-encoding&quot;: &quot;gzip, deflate, br&quot;,</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        &quot;accept-language&quot;: &quot;zh-CN,zh;q=0.9,en-CN;q=0.8,en;q=0.7,ja-CN;q=0.6,ja;q=0.5&quot;,</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        &quot;x-requested-with&quot;: &quot;xmlhttprequest&quot;,</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        &quot;user-agent&quot;: &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 \\</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        (KHTML, like Gecko) Chrome/77.0.3865.90 Safari/537.36&quot;</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">    &#125;</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">    # 构建参数</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">    params = &#123;</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        &#39;p&#39;: page,</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        &#39;ttype&#39;: &#39;illust&#39;,</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        &#39;sub_type&#39;: &#39;week&#39;,</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        &#39;date&#39;: &#39;20190923&#39;</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">    &#125;</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">    # 利用urlencode将参数解析为带有&quot;&amp;&quot;链接的的字符串，和base_url组成可以访问的链接。</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">    url = base_url + urlencode(params)</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">    txt = requests.get(url, headers=headers, timeout=50)</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">    if txt.status_code == 200:</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        return txt.json()  # 返回json文件</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">    else:</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        return None</span></span>\n<span class=\"line\"><span style=\"color: #babed8\"></span></span>\n<span class=\"line\"><span style=\"color: #babed8\"></span></span>\n<span class=\"line\"><span style=\"color: #babed8\"># 解析，不过由于返回的是json文件，可以利用json的特点（类似字典）来查找自己需要找的信息。</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">def parse_page(json):</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">    if json:</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        for i in range(20):</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">            ls = json[&#39;data&#39;][&#39;top_list_item_info&#39;][i][&#39;item_detail&#39;][&#39;multi&#39;]</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">            for item in ls:</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">                links.append(item[&#39;path&#39;])</span></span>\n<span class=\"line\"><span style=\"color: #babed8\"></span></span>\n<span class=\"line\"><span style=\"color: #babed8\"></span></span>\n<span class=\"line\"><span style=\"color: #babed8\">def Image_save(links, num):</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">    for i in range(1, num + 1):</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        html = requests.get(links[i - 1])</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        with open(&quot;./Image/&#123;&#125;.jpg&quot;.format(i), &quot;wb&quot;) as f:</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">            f.write(html.content)</span></span>\n<span class=\"line\"><span style=\"color: #babed8\"></span></span>\n<span class=\"line\"><span style=\"color: #babed8\"></span></span>\n<span class=\"line\"><span style=\"color: #babed8\">if __name__ == &quot;__main__&quot;:</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">    for page in range(1, 4):</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        json = getHTMLText(page)</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        parse_page(json)</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">    length = len(links)</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">    Image_save(links, length)</span></span></code></pre></div><p>对了，大家如果有时间，可以看看保存在Github的这个代码：<a href=\"https://github.com/liuweixu/Python-crawler/blob/master/Ajax/%E5%8D%8A%E6%AC%A1%E5%85%83%E5%91%A8%E6%A6%9C%E9%83%A8%E5%88%86%E7%88%AC%E8%99%AB.py\">Ajax处理</a></p>\n<h4 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a>参考链接</h4><ul>\n<li><a href=\"https://cuiqingcai.com/5590.html\">崔庆才博客</a></li>\n<li>《Python3网络爬虫》崔庆才</li>\n</ul>\n","text":"Ajax数据爬取的一个简单的例子 前言这个是在动态页面的爬虫，而一般来说，现在大部分动态页面通过Ajax加载的，Ajax即Asynchronous Javasc...","permalink":"/post/Ajax处理之半次元周榜部分爬虫","photos":[],"count_time":{"symbolsCount":"4.5k","symbolsTime":"4 mins."},"categories":[],"tags":[{"name":"爬虫","slug":"爬虫","count":6,"path":"api/tags/爬虫.json"},{"name":"Python","slug":"Python","count":1,"path":"api/tags/Python.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E5%89%8D%E8%A8%80\"><span class=\"toc-text\">前言</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E7%A1%AE%E5%AE%9A%E9%A1%B5%E9%9D%A2%E7%9A%84%E7%B1%BB%E5%9E%8B\"><span class=\"toc-text\">确定页面的类型</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#Ajax%E5%88%86%E6%9E%90\"><span class=\"toc-text\">Ajax分析</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#Ajax%E7%88%AC%E5%8F%96\"><span class=\"toc-text\">Ajax爬取</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E5%85%A8%E9%83%A8%E4%BB%A3%E7%A0%81%EF%BC%9A\"><span class=\"toc-text\">全部代码：</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5\"><span class=\"toc-text\">参考链接</span></a></li></ol>","author":{"name":"Aurora","slug":"blog-author","avatar":"","link":"/","description":"","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"mapped":true,"hidden":false,"prev_post":{"title":"(brute force, implementation)A. Fafa and his Company","uid":"34d456b5a83eea087e8a8a1bd513e081","slug":"brute-force-implementation-A-Fafa-and-his-Company","date":"2020-09-06T02:35:56.000Z","updated":"2023-09-06T07:13:11.750Z","comments":true,"path":"api/articles/brute-force-implementation-A-Fafa-and-his-Company.json","keywords":null,"cover":null,"text":"水题 题目链接：935A - Fafa and his Company A. Fafa and his CompanyFafa owns a company t...","permalink":"/post/brute-force-implementation-A-Fafa-and-his-Company","photos":[],"count_time":{"symbolsCount":"2.2k","symbolsTime":"2 mins."},"categories":[],"tags":[{"name":"刷题：","slug":"刷题：","count":1,"path":"api/tags/刷题：.json"}],"author":{"name":"Aurora","slug":"blog-author","avatar":"","link":"/","description":"","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}},"next_post":{"title":"Ubuntu18.04 主题美化（MaxOS主题）","uid":"1559d2cf4b481d8b25de999a80211dc5","slug":"Ubuntu18-04-主题美化（MaxOS主题）","date":"2019-09-10T01:56:43.000Z","updated":"2023-09-06T07:14:24.883Z","comments":true,"path":"api/articles/Ubuntu18-04-主题美化（MaxOS主题）.json","keywords":null,"cover":[],"text":" Ubuntu时可以进行主题的美化，可以改为MacOS主题。 安装工具要安装主题，首先要安装三个包 txtsudo apt update sudo apt in...","permalink":"/post/Ubuntu18-04-主题美化（MaxOS主题）","photos":[],"count_time":{"symbolsCount":"2.3k","symbolsTime":"2 mins."},"categories":[],"tags":[{"name":"Linux","slug":"Linux","count":3,"path":"api/tags/Linux.json"},{"name":"Ubuntu","slug":"Ubuntu","count":3,"path":"api/tags/Ubuntu.json"}],"author":{"name":"Aurora","slug":"blog-author","avatar":"","link":"/","description":"","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}}}