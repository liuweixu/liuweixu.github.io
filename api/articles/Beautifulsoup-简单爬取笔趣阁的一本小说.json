{"title":"Beautifulsoup 简单爬取笔趣阁的一本小说","uid":"3c1bb9fa0166d0dcb073cf074128c466","slug":"Beautifulsoup-简单爬取笔趣阁的一本小说","date":"2021-07-03T03:23:00.000Z","updated":"2023-09-06T07:12:09.436Z","comments":true,"path":"api/articles/Beautifulsoup-简单爬取笔趣阁的一本小说.json","keywords":null,"cover":null,"content":"<p>我写这个代码的主要目的是针对一个关于上面的题目的博文进行修改，其实，这个博文讲的不错，但是由于网站更新了，他的代码有些地方是不灵的。所以我就修改了一些。</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p><a href=\"https://www.w3cschool.cn/python3/python3-enbl2pw9.html\">这个博文</a></p></blockquote>\n<p>修改后的代码：(解释见注释)</p>\n<div class=\"language-txt\"><button title=\"Copy code\" class=\"copy\"></button><span class=\"lang\">txt</span><pre class=\"shiki material-theme-palenight\" style=\"background-color: #1a1a1a\" tabindex=\"0\"><code><span class=\"line\"><span style=\"color: #babed8\">from bs4 import BeautifulSoup</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">import requests, sys</span></span>\n<span class=\"line\"><span style=\"color: #babed8\"></span></span>\n<span class=\"line\"><span style=\"color: #babed8\">class downloader(object):</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">    def __init__(self):</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        self.server = &quot;http://www.biqukan.com/&quot;</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        self.target = &quot;http://www.biqukan.com/1_1094/&quot;</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        self.name = []</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        self.url = []</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        self.nums = 0</span></span>\n<span class=\"line\"><span style=\"color: #babed8\"></span></span>\n<span class=\"line\"><span style=\"color: #babed8\">    def get_download_url(self):</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        req = requests.get(url = self.target)   # 获取网页的内容。</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        req.encoding = req.apparent_encoding    # 为了防止出现乱码，如果没有加这个的话，会出现乱码的。</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        html = req.text</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        div_soup = BeautifulSoup(html, &quot;lxml&quot;)  # 解析，注意要加上&#39;lxml&#39;</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        div = div_soup.find_all(&#39;div&#39;, class_ = &#39;listmain&#39;) # div的类型是bs4.element.ResultSet，是一个列表，不过在这个列表中，它的长度仅为1。</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">                                                            # 所以用div[0]读取内容。</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        a_soup = BeautifulSoup(str(div[0]), &quot;lxml&quot;) # Beautifulsoup()里面传入的是str类型。</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        a = a_soup.find_all(&#39;a&#39;)</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        self.nums = len(a[16:])</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        for i in a[16:]:</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">            self.name.append(i.string)</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">            self.url.append(self.server + i.get(&#39;href&#39;))    # i.get(&#39;href&#39;)是str类型。</span></span>\n<span class=\"line\"><span style=\"color: #babed8\"></span></span>\n<span class=\"line\"><span style=\"color: #babed8\">    def get_content(self, target):</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        req = requests.get(target)</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        req.encoding = req.apparent_encoding    # 这个也是为了防止出现乱码的。</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        html = req.text</span></span>\n<span class=\"line\"><span style=\"color: #babed8\"></span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        soup = BeautifulSoup(html, &#39;lxml&#39;)</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        texts = soup.find_all(&#39;div&#39;, class_ = &#39;showtxt&#39;)</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        texts = texts[0].text.replace(&#39; &#39;,&#39;\\n&#39;).replace(&#39;\\xa0&#39;*8,&#39; &#39;) # 这个我不懂为什么为什么要加这个。反正只要加了这个，</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">                                                                      # 就会输出需要的内容。</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        return texts</span></span>\n<span class=\"line\"><span style=\"color: #babed8\"></span></span>\n<span class=\"line\"><span style=\"color: #babed8\">    def writer(self, name, path, text):</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        with open(path, &#39;a&#39;, encoding= &#39;utf-8&#39;) as f:</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">            f.write(name + &#39;\\n&#39;)</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">            f.writelines(text)</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">            f.write(&#39;\\n\\n&#39;)</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">if __name__ == &#39;__main__&#39;:</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">    dl = downloader()</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">    dl.get_download_url()</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">    print(&quot;开始下载：&quot;)</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">    for i in range(dl.nums):</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        dl.writer(dl.name[i], &#39;一念永恒.txt&#39;, dl.get_content(dl.url[i]))</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        # print(&quot;  已下载:%.3f%%&quot; %  float(i/dl.nums) + &#39;\\r&#39;)</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        sys.stdout.write(&quot;\\r&quot; + &quot;已下载:%.2f%%&quot; %  float(100.0 * i/dl.nums)) # 在一行动态输出，下面的一行也必须要写。</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        sys.stdout.flush()</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">    print(&quot;下载结束&quot;)</span></span></code></pre></div><p>其中，关于在一行动态输出的博文可以见：<br><a href=\"https://blog.csdn.net/weixin_33736048/article/details/86263346\">python实现原地刷新方式输出-可用于百分比进度显示输出_weixin_33736048的博客-CSDN博客</a></p>\n","text":"我写这个代码的主要目的是针对一个关于上面的题目的博文进行修改，其实，这个博文讲的不错，但是由于网站更新了，他的代码有些地方是不灵的。所以我就修改了一些。 这个博...","permalink":"/post/Beautifulsoup-简单爬取笔趣阁的一本小说","photos":[],"count_time":{"symbolsCount":"2.5k","symbolsTime":"2 mins."},"categories":[],"tags":[{"name":"爬虫","slug":"爬虫","count":6,"path":"api/tags/爬虫.json"}],"toc":"","author":{"name":"Aurora","slug":"blog-author","avatar":"","link":"/","description":"","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"mapped":true,"hidden":false,"prev_post":{"title":"scrapy爬取笔趣看的小说","uid":"acb53f06d1c58527ddd8b9d7be584840","slug":"scrapy爬取笔趣看的小说","date":"2021-07-07T04:47:28.000Z","updated":"2023-09-06T07:12:47.845Z","comments":true,"path":"api/articles/scrapy爬取笔趣看的小说.json","keywords":null,"cover":null,"text":"前言之前用了requests和Beautifulsoup爬取笔趣看的小说了《极品家丁》，不过现在用爬虫框架——Scrapy爬取，这个框架比较好用，自带分布式，可...","permalink":"/post/scrapy爬取笔趣看的小说","photos":[],"count_time":{"symbolsCount":"5.2k","symbolsTime":"5 mins."},"categories":[],"tags":[{"name":"爬虫","slug":"爬虫","count":6,"path":"api/tags/爬虫.json"}],"author":{"name":"Aurora","slug":"blog-author","avatar":"","link":"/","description":"","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}},"next_post":{"title":"Beautifulsoup和requests爬取笔趣看","uid":"57287119be964990fe44e1874987acf7","slug":"Beautifulsoup和requests爬取笔趣看","date":"2021-07-01T03:46:00.000Z","updated":"2023-09-06T07:11:57.406Z","comments":true,"path":"api/articles/Beautifulsoup和requests爬取笔趣看.json","keywords":null,"cover":[],"text":" 这个是用来爬取笔趣看的一本书的所有文章，理论上可以成功地爬取笔趣看的每本书。 关于讲解这个代码之前，我觉得需要注意的一些必要的内容： 这个爬虫实质上就是利用某...","permalink":"/post/Beautifulsoup和requests爬取笔趣看","photos":[],"count_time":{"symbolsCount":"3.5k","symbolsTime":"3 mins."},"categories":[],"tags":[{"name":"爬虫","slug":"爬虫","count":6,"path":"api/tags/爬虫.json"}],"author":{"name":"Aurora","slug":"blog-author","avatar":"","link":"/","description":"","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}}}