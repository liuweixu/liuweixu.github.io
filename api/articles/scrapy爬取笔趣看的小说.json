{"title":"scrapy爬取笔趣看的小说","uid":"acb53f06d1c58527ddd8b9d7be584840","slug":"scrapy爬取笔趣看的小说","date":"2021-07-07T04:47:28.000Z","updated":"2023-09-06T07:12:47.845Z","comments":true,"path":"api/articles/scrapy爬取笔趣看的小说.json","keywords":null,"cover":null,"content":"<h3 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h3><p>之前用了requests和Beautifulsoup爬取笔趣看的小说了<a href=\"https://liuweixu.github.io/2019/10/01/Beautifulsoup/#more\">《极品家丁》</a>，不过现在用爬虫框架——Scrapy爬取，这个框架比较好用，自带分布式，可以让我们省下时间快速爬取自己需要的内容，这个是一个很优秀的轮子，我们干嘛不能学和用呢？不过这个scrapy学习相对来说比较难上手。</p>\n<h3 id=\"开始入门\"><a href=\"#开始入门\" class=\"headerlink\" title=\"开始入门\"></a>开始入门</h3><h4 id=\"准备工作\"><a href=\"#准备工作\" class=\"headerlink\" title=\"准备工作\"></a>准备工作</h4><p>安装好Scrapy，在windows可以用pip install scrapy就安装好，其他的可以看看<a href=\"https://cuiqingcai.com/5421.html\">崔庆才博客</a></p>\n<h4 id=\"创建项目\"><a href=\"#创建项目\" class=\"headerlink\" title=\"创建项目\"></a>创建项目</h4><div class=\"language-python\"><button title=\"Copy code\" class=\"copy\"></button><span class=\"lang\">python</span><pre class=\"shiki material-theme-palenight\" style=\"background-color: #1a1a1a\" tabindex=\"0\"><code><span class=\"line\"><span style=\"color: #BABED8\">scrapy startproject Jipin</span></span></code></pre></div><p>这个可以在cmd的命令行运行，也可以在Pycharm的下面的Terminal运行，我用的是Pycharm，所以接下来的步骤都是在Pycharm上运行的，不在Pycharm的，也可以运行的。</p>\n<h4 id=\"创建Spider\"><a href=\"#创建Spider\" class=\"headerlink\" title=\"创建Spider\"></a>创建Spider</h4><div class=\"language-python\"><button title=\"Copy code\" class=\"copy\"></button><span class=\"lang\">python</span><pre class=\"shiki material-theme-palenight\" style=\"background-color: #1a1a1a\" tabindex=\"0\"><code><span class=\"line\"><span style=\"color: #BABED8\">cd Jipin</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">scrapy genspider jipinjiading www</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #F07178\">biqukan</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #F07178\">com</span><span style=\"color: #89DDFF\">/</span><span style=\"color: #F78C6C\">3_3053</span></span></code></pre></div><p>然后在Pycharm打开Jipin文件夹。</p>\n<h4 id=\"开始编写代码\"><a href=\"#开始编写代码\" class=\"headerlink\" title=\"开始编写代码\"></a>开始编写代码</h4><ul>\n<li><p>首先在items.py中,需要定义item（也可以不用定义Item），这个Item可以理解为字典，下面的两行可以认为是定义字典的键。</p>\n<div class=\"language-python\"><button title=\"Copy code\" class=\"copy\"></button><span class=\"lang\">python</span><pre class=\"shiki material-theme-palenight\" style=\"background-color: #1a1a1a\" tabindex=\"0\"><code><span class=\"line\"><span style=\"color: #676E95; font-style: italic\"># -*- coding: utf-8 -*-</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF; font-style: italic\">import</span><span style=\"color: #BABED8\"> scrapy</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF; font-style: italic\">from</span><span style=\"color: #BABED8\"> urllib </span><span style=\"color: #89DDFF; font-style: italic\">import</span><span style=\"color: #BABED8\"> parse</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF; font-style: italic\">from</span><span style=\"color: #BABED8\"> Jipin</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #BABED8\">items </span><span style=\"color: #89DDFF; font-style: italic\">import</span><span style=\"color: #BABED8\"> JipinItem</span></span></code></pre></div><p>class JipinjiadingSpider(scrapy.Spider):</p>\n<div class=\"language-txt\"><button title=\"Copy code\" class=\"copy\"></button><span class=\"lang\">txt</span><pre class=\"shiki material-theme-palenight\" style=\"background-color: #1a1a1a\" tabindex=\"0\"><code><span class=\"line\"><span style=\"color: #babed8\">name = &#39;jipinjiading&#39;</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">allowed_domains = [&#39;www.biqukan.com&#39;]</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">start_urls = [&#39;http://www.biqukan.com/3_3053/&#39;]</span></span>\n<span class=\"line\"><span style=\"color: #babed8\"></span></span>\n<span class=\"line\"><span style=\"color: #babed8\"># 抓取目录页的标题的链接</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">def parse(self, response):</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">    links = response.css(&quot;.listmain dl dd a::attr(href)&quot;).extract()</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">    for link in links:</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        yield scrapy.Request(url=parse.urljoin(response.url, link), callback=self.parse_page)</span></span>\n<span class=\"line\"><span style=\"color: #babed8\"></span></span>\n<span class=\"line\"><span style=\"color: #babed8\"># 抓取文章页面的标题和内容。</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">def parse_page(self, response):</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">    item = JipinItem()</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">    item[&#39;title&#39;] = response.css(&quot;.content h1::text&quot;).extract_first()</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">    texts = response.xpath(&quot;//*[@id=\\&quot;content\\&quot;]/text()&quot;).extract()</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">    item[&#39;text&#39;] = &quot;&quot;.join(texts).replace(&quot;\\xa0&quot; * 8, &quot;&quot;)</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">    yield item</span></span></code></pre></div></li>\n</ul>\n<div class=\"language-txt\"><button title=\"Copy code\" class=\"copy\"></button><span class=\"lang\">txt</span><pre class=\"shiki material-theme-palenight\" style=\"background-color: #1a1a1a\" tabindex=\"0\"><code><span class=\"line\"><span style=\"color: #babed8\">- spider/jipinjiading.py</span></span>\n<span class=\"line\"><span style=\"color: #babed8\"></span></span>\n<span class=\"line\"><span style=\"color: #babed8\">```python</span></span>\n<span class=\"line\"><span style=\"color: #babed8\"># -*- coding: utf-8 -*-</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">import scrapy</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">from urllib import parse</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">from Jipin.items import JipinItem</span></span>\n<span class=\"line\"><span style=\"color: #babed8\"></span></span>\n<span class=\"line\"><span style=\"color: #babed8\"></span></span>\n<span class=\"line\"><span style=\"color: #babed8\">class JipinjiadingSpider(scrapy.Spider):</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">    name = &#39;jipinjiading&#39;</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">    allowed_domains = [&#39;www.biqukan.com&#39;]</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">    start_urls = [&#39;http://www.biqukan.com/3_3053/&#39;]</span></span>\n<span class=\"line\"><span style=\"color: #babed8\"></span></span>\n<span class=\"line\"><span style=\"color: #babed8\">    # 抓取目录页的标题的链接</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">    def parse(self, response):</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        links = response.css(&quot;.listmain dl dd a::attr(href)&quot;).extract()</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        for link in links:</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">            yield scrapy.Request(url=parse.urljoin(response.url, link), callback=self.parse_page)</span></span>\n<span class=\"line\"><span style=\"color: #babed8\"></span></span>\n<span class=\"line\"><span style=\"color: #babed8\">    # 抓取文章页面的标题和内容。</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">    def parse_page(self, response):</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        item = JipinItem()</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        item[&#39;title&#39;] = response.css(&quot;.content h1::text&quot;).extract_first()</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        texts = response.xpath(&quot;//*[@id=\\&quot;content\\&quot;]/text()&quot;).extract()</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        item[&#39;text&#39;] = &quot;&quot;.join(texts).replace(&quot;\\xa0&quot; * 8, &quot;&quot;)</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        yield item</span></span></code></pre></div><p>  注意这个allowed_domains 里面的是域名，start_urls里面的可以是小说的目录页的链接。接下来就是爬取了。</p>\n<p>  在抓取目录页的标题的链接中，parse()方法的参数response是start_urls里面的链接爬取后的结果，所以在parse()方法中，我们可以直接对response变量包含的内容进行解析，解析的方式有正则表达式，Xpath或css选择器。有：</p>\n<div class=\"language-python\"><button title=\"Copy code\" class=\"copy\"></button><span class=\"lang\">python</span><pre class=\"shiki material-theme-palenight\" style=\"background-color: #1a1a1a\" tabindex=\"0\"><code><span class=\"line\"><span style=\"color: #BABED8\">links </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> response</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">css</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">.listmain dl dd a::attr(href)</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #89DDFF\">).</span><span style=\"color: #82AAFF\">extract</span><span style=\"color: #89DDFF\">()</span></span></code></pre></div><p>  其中，extract()里的extract的意思是提取，它的作用就是对于response.css()或response.xpath()获取的结果提取为整个列表。</p>\n<p>  然后循环遍历</p>\n<div class=\"language-python\"><button title=\"Copy code\" class=\"copy\"></button><span class=\"lang\">python</span><pre class=\"shiki material-theme-palenight\" style=\"background-color: #1a1a1a\" tabindex=\"0\"><code><span class=\"line\"><span style=\"color: #89DDFF; font-style: italic\">for</span><span style=\"color: #BABED8\"> link </span><span style=\"color: #89DDFF; font-style: italic\">in</span><span style=\"color: #BABED8\"> links</span><span style=\"color: #89DDFF\">:</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">    </span><span style=\"color: #89DDFF; font-style: italic\">yield</span><span style=\"color: #BABED8\"> scrapy</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">Request</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #BABED8; font-style: italic\">url</span><span style=\"color: #89DDFF\">=</span><span style=\"color: #82AAFF\">parse</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">urljoin</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #82AAFF\">response</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #F07178\">url</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> link</span><span style=\"color: #89DDFF\">),</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #BABED8; font-style: italic\">callback</span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\">self</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #F07178\">parse_page</span><span style=\"color: #89DDFF\">)</span></span></code></pre></div><p>  这两行代码比较重要，也比较难理解。</p>\n<ol>\n<li><p>scrapy会根据<strong>yield</strong>返回的示例类型来执行不同的操作。在上面的代码中，对于scrapy.Request对象，scrapy框架会去获得该对象指向的链接并在请求完成后调用该对象的回调函数。</p>\n</li>\n<li><p>在callback回调函数中，我个人觉得就是对于这个scrapy.Request()获取的链接调到这个回调函数，而回调函数里面会对这个链接的内容进一步处理，得到需要的内容。</p>\n<p>在parse_page()函数中，这个作用就是使用item，把上面的回调过来的链接用Request获取内容作为值赋值给item，然后用yield把这个item传给Item Pipeline。</p>\n<div class=\"language-python\"><button title=\"Copy code\" class=\"copy\"></button><span class=\"lang\">python</span><pre class=\"shiki material-theme-palenight\" style=\"background-color: #1a1a1a\" tabindex=\"0\"><code><span class=\"line\"><span style=\"color: #676E95; font-style: italic\"># -*- coding: utf-8 -*-</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF; font-style: italic\">import</span><span style=\"color: #BABED8\"> scrapy</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF; font-style: italic\">from</span><span style=\"color: #BABED8\"> urllib </span><span style=\"color: #89DDFF; font-style: italic\">import</span><span style=\"color: #BABED8\"> parse</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF; font-style: italic\">from</span><span style=\"color: #BABED8\"> Jipin</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #BABED8\">items </span><span style=\"color: #89DDFF; font-style: italic\">import</span><span style=\"color: #BABED8\"> JipinItem</span></span></code></pre></div><p>class JipinjiadingSpider(scrapy.Spider):<br>   name &#x3D; ‘jipinjiading’<br>   allowed_domains &#x3D; [‘<a href=\"http://www.biqukan.com']\">www.biqukan.com&#39;]</a><br>   start_urls &#x3D; [‘<a href=\"http://www.biqukan.com/3_3053/']\">http://www.biqukan.com/3_3053/&#39;]</a></p>\n<h1 id=\"抓取目录页的标题的链接\"><a href=\"#抓取目录页的标题的链接\" class=\"headerlink\" title=\"抓取目录页的标题的链接\"></a>抓取目录页的标题的链接</h1><p>   def parse(self, response):</p>\n<div class=\"language-txt\"><button title=\"Copy code\" class=\"copy\"></button><span class=\"lang\">txt</span><pre class=\"shiki material-theme-palenight\" style=\"background-color: #1a1a1a\" tabindex=\"0\"><code><span class=\"line\"><span style=\"color: #babed8\">   links = response.css(&quot;.listmain dl dd a::attr(href)&quot;).extract()</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">   for link in links:</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">       yield scrapy.Request(url=parse.urljoin(response.url, link), callback=self.parse_page)</span></span></code></pre></div><h1 id=\"抓取文章页面的标题和内容。\"><a href=\"#抓取文章页面的标题和内容。\" class=\"headerlink\" title=\"抓取文章页面的标题和内容。\"></a>抓取文章页面的标题和内容。</h1><p>   def parse_page(self, response):</p>\n<div class=\"language-txt\"><button title=\"Copy code\" class=\"copy\"></button><span class=\"lang\">txt</span><pre class=\"shiki material-theme-palenight\" style=\"background-color: #1a1a1a\" tabindex=\"0\"><code><span class=\"line\"><span style=\"color: #babed8\">   item = JipinItem()</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">   item[&#39;title&#39;] = response.css(&quot;.content h1::text&quot;).extract_first()</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">   texts = response.xpath(&quot;//*[@id=\\&quot;content\\&quot;]/text()&quot;).extract()</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">   item[&#39;text&#39;] = &quot;&quot;.join(texts).replace(&quot;\\xa0&quot; * 8, &quot;&quot;)</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">   yield item # 这个是难点，需要理解。</span></span></code></pre></div></li>\n</ol>\n<div class=\"language-txt\"><button title=\"Copy code\" class=\"copy\"></button><span class=\"lang\">txt</span><pre class=\"shiki material-theme-palenight\" style=\"background-color: #1a1a1a\" tabindex=\"0\"><code><span class=\"line\"><span style=\"color: #babed8\">- pipelines.py</span></span>\n<span class=\"line\"><span style=\"color: #babed8\"></span></span>\n<span class=\"line\"><span style=\"color: #babed8\">这个是Item Pipeline，即项目管道。面对Spider传递过来的**一个一个**的item，获取item的内容，保存到文件中。</span></span>\n<span class=\"line\"><span style=\"color: #babed8\"></span></span>\n<span class=\"line\"><span style=\"color: #babed8\">```python</span></span>\n<span class=\"line\"><span style=\"color: #babed8\"># -*- coding: utf-8 -*-</span></span>\n<span class=\"line\"><span style=\"color: #babed8\"></span></span>\n<span class=\"line\"><span style=\"color: #babed8\"># Define your item pipelines here</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">#</span></span>\n<span class=\"line\"><span style=\"color: #babed8\"># Don&#39;t forget to add your pipeline to the ITEM_PIPELINES setting</span></span>\n<span class=\"line\"><span style=\"color: #babed8\"># See: https://docs.scrapy.org/en/latest/topics/item-pipeline.html</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">import os</span></span>\n<span class=\"line\"><span style=\"color: #babed8\"></span></span>\n<span class=\"line\"><span style=\"color: #babed8\"></span></span>\n<span class=\"line\"><span style=\"color: #babed8\">class JipinPipeline(object):</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">    def process_item(self, item, spider):</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        try:</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">            path = &quot;Jipinjiading&quot;</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">            if not os.path.exists(path):</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">                os.makedirs(path)</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">            text = item[&#39;text&#39;]</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">            title = item[&#39;title&#39;]</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">            print(len(title))</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">            with open(&quot;./&quot; + path + &quot;/&#123;&#125;.txt&quot;.format(title), &quot;w&quot;, encoding=&quot;utf-8&quot;) as f:</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">                f.write(text)</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        except:</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">            pass</span></span>\n<span class=\"line\"><span style=\"color: #babed8\">        return item</span></span></code></pre></div><p>  注意<strong>不能用数组</strong>，比如*for i in item[‘text’]*等等，因为由于是异步，所以Spider是<strong>一个一个</strong>向Item Pipeline传递item，而每个item一般包含一组信息。而这个Item Pipeline则会一个一个处理item，这个循环是内定的。我这么理解的。</p>\n<ul>\n<li><p>settings.py</p>\n<div class=\"language-python\"><button title=\"Copy code\" class=\"copy\"></button><span class=\"lang\">python</span><pre class=\"shiki material-theme-palenight\" style=\"background-color: #1a1a1a\" tabindex=\"0\"><code><span class=\"line\"><span style=\"color: #BABED8\">ITEM_PIPELINES </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">&#123;</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">   </span><span style=\"color: #89DDFF\">&#39;</span><span style=\"color: #C3E88D\">Jipin.pipelines.JipinPipeline</span><span style=\"color: #89DDFF\">&#39;</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #BABED8\"> </span><span style=\"color: #F78C6C\">300</span><span style=\"color: #89DDFF\">,</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">&#125;</span></span></code></pre></div><p>这个需要去掉注释，如果不这样做，就不能实现将Item Pipeline 的作用了。</p>\n</li>\n</ul>\n<h4 id=\"Github\"><a href=\"#Github\" class=\"headerlink\" title=\"Github\"></a>Github</h4><p>这些完整的代码见于：<a href=\"https://github.com/liuweixu/Python-crawler/tree/master/Scrapy/%E7%88%AC%E5%8F%96%E3%80%8A%E6%9E%81%E5%93%81%E5%AE%B6%E4%B8%81%E3%80%8B%E5%B0%8F%E8%AF%B4/Jipin\">Github</a></p>\n<h3 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h3><ul>\n<li>《Python3 网络爬虫开发实战》崔庆才</li>\n</ul>\n","text":"前言之前用了requests和Beautifulsoup爬取笔趣看的小说了《极品家丁》，不过现在用爬虫框架——Scrapy爬取，这个框架比较好用，自带分布式，可...","permalink":"/post/scrapy爬取笔趣看的小说","photos":[],"count_time":{"symbolsCount":"5.2k","symbolsTime":"5 mins."},"categories":[],"tags":[{"name":"爬虫","slug":"爬虫","count":6,"path":"api/tags/爬虫.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%89%8D%E8%A8%80\"><span class=\"toc-text\">前言</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%BC%80%E5%A7%8B%E5%85%A5%E9%97%A8\"><span class=\"toc-text\">开始入门</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E5%87%86%E5%A4%87%E5%B7%A5%E4%BD%9C\"><span class=\"toc-text\">准备工作</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E5%88%9B%E5%BB%BA%E9%A1%B9%E7%9B%AE\"><span class=\"toc-text\">创建项目</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E5%88%9B%E5%BB%BASpider\"><span class=\"toc-text\">创建Spider</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E5%BC%80%E5%A7%8B%E7%BC%96%E5%86%99%E4%BB%A3%E7%A0%81\"><span class=\"toc-text\">开始编写代码</span></a></li></ol></li></ol></li></ol></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E6%8A%93%E5%8F%96%E7%9B%AE%E5%BD%95%E9%A1%B5%E7%9A%84%E6%A0%87%E9%A2%98%E7%9A%84%E9%93%BE%E6%8E%A5\"><span class=\"toc-text\">抓取目录页的标题的链接</span></a></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E6%8A%93%E5%8F%96%E6%96%87%E7%AB%A0%E9%A1%B5%E9%9D%A2%E7%9A%84%E6%A0%87%E9%A2%98%E5%92%8C%E5%86%85%E5%AE%B9%E3%80%82\"><span class=\"toc-text\">抓取文章页面的标题和内容。</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#Github\"><span class=\"toc-text\">Github</span></a></li></ol></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%8F%82%E8%80%83\"><span class=\"toc-text\">参考</span></a></li></ol>","author":{"name":"Aurora","slug":"blog-author","avatar":"","link":"/","description":"","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"mapped":true,"hidden":false,"prev_post":{"title":"Scrapy爬取Bing美图","uid":"74b3c9299a9d2a5ecfa2b1ca58a5ff0a","slug":"Scrapy爬取Bing美图","date":"2021-07-10T04:59:38.000Z","updated":"2023-09-06T07:12:36.297Z","comments":true,"path":"api/articles/Scrapy爬取Bing美图.json","keywords":null,"cover":null,"text":" 这个是Image Pipeline 练习 确定爬取的目标我们要爬取的是Bing美图，Bing今日美图，我们可以发现，这个网页没有ajax加载，有页面，其中UR...","permalink":"/post/Scrapy爬取Bing美图","photos":[],"count_time":{"symbolsCount":"3.1k","symbolsTime":"3 mins."},"categories":[],"tags":[{"name":"爬虫","slug":"爬虫","count":6,"path":"api/tags/爬虫.json"}],"author":{"name":"Aurora","slug":"blog-author","avatar":"","link":"/","description":"","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}},"next_post":{"title":"Beautifulsoup 简单爬取笔趣阁的一本小说","uid":"3c1bb9fa0166d0dcb073cf074128c466","slug":"Beautifulsoup-简单爬取笔趣阁的一本小说","date":"2021-07-03T03:23:00.000Z","updated":"2023-09-06T07:12:09.436Z","comments":true,"path":"api/articles/Beautifulsoup-简单爬取笔趣阁的一本小说.json","keywords":null,"cover":null,"text":"我写这个代码的主要目的是针对一个关于上面的题目的博文进行修改，其实，这个博文讲的不错，但是由于网站更新了，他的代码有些地方是不灵的。所以我就修改了一些。 这个博...","permalink":"/post/Beautifulsoup-简单爬取笔趣阁的一本小说","photos":[],"count_time":{"symbolsCount":"2.5k","symbolsTime":"2 mins."},"categories":[],"tags":[{"name":"爬虫","slug":"爬虫","count":6,"path":"api/tags/爬虫.json"}],"author":{"name":"Aurora","slug":"blog-author","avatar":"","link":"/","description":"","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}}}